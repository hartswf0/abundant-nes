<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover" />
<title>Echoes & Algorithms â€” Live Audio Presentation</title>
<style>
  :root{
    --bg:#0b0c0f; --fg:#e8eaf0; --muted:#a6adbf; --accent:#7aa2ff; --accent2:#8af5c8; --warn:#ffb86b; --danger:#ff6b6b;
    --card:#12141a; --ghost:#0b0c0f; --grid:#18202c; --ok:#9eedb8;
  }
  [data-theme="light"]{ --bg:#f8fafc; --fg:#0b1220; --muted:#4b5563; --accent:#1e40af; --accent2:#059669; --card:#ffffff; --grid:#e5e7eb; --ghost:#f8fafc }
  html,body{height:100%;}
  body{margin:0;font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Inter,Helvetica,Arial; background:var(--bg); color:var(--fg);}
  .app{display:grid; grid-template-rows:auto 1fr auto; min-height:100dvh;}
  header{position:sticky;top:0; z-index:3; backdrop-filter: blur(8px); background:linear-gradient(180deg, rgba(0,0,0,.35), transparent);}
  .bar{display:flex; gap:.5rem; align-items:center; padding: env(safe-area-inset-top) clamp(.75rem,2vw,1rem) .75rem clamp(.75rem,2vw,1rem);} 
  .title{font-weight:700; letter-spacing:.2px}
  .spacer{flex:1}
  button,select,input[type="range"]{background:var(--card); color:var(--fg); border:1px solid var(--grid); border-radius:14px; padding:.6rem .9rem; font-weight:600; box-shadow:0 1px 0 rgba(255,255,255,.04) inset, 0 8px 30px rgba(0,0,0,.15);}
  button.icon{padding:.55rem; width:42px; height:42px; display:grid; place-items:center}
  button[disabled]{opacity:.5}
  .cta{background:linear-gradient(135deg,var(--accent),var(--accent2)); color:#061019; border:none}
  .main{position:relative; overflow:hidden}
  canvas{position:absolute; inset:0; width:100%; height:100%; display:block; background:radial-gradient(1200px 800px at 60% -10%, rgba(122,162,255,.15), transparent),
                                    radial-gradient(900px 900px at -10% 120%, rgba(138,245,200,.10), transparent),
                                    conic-gradient(from 180deg at 50% 50%, rgba(255,255,255,.02), rgba(255,255,255,.008), rgba(255,255,255,.02));}
  .overlay{position:absolute; inset:0; display:grid; grid-template-rows:1fr auto; pointer-events:none}
  .center{display:grid; place-items:center; padding:2rem}
  .now{ max-width:900px; padding:1rem 1.25rem; border-radius:18px; background:color-mix(in oklab, var(--card) 80%, transparent); border:1px solid var(--grid); box-shadow:0 10px 40px rgba(0,0,0,.25)}
  .now h1{margin:.2rem 0 .4rem; font-size:clamp(1.25rem, 3vw, 1.75rem); line-height:1.1}
  .now p{margin:.25rem 0; color:var(--muted)}
  .cue{font-family:ui-monospace,SFMono-Regular,Menlo,monospace; font-weight:700; letter-spacing:.6px; color:var(--accent)}
  .bottom{display:grid; gap:.5rem; padding: 1rem; pointer-events:auto}
  .transport{display:flex; gap:.5rem; flex-wrap:wrap}
  .meters{display:flex; gap:1rem; align-items:center; flex-wrap:wrap}
  .meter{width:160px}
  .progress{position:relative; height:10px; background:var(--grid); border-radius:999px; overflow:hidden}
  .progress > i{position:absolute; inset:0; background:linear-gradient(90deg,var(--accent),var(--accent2)); width:0%;}
  .legend{display:flex; gap:.75rem; flex-wrap:wrap; font-size:.85rem; color:var(--muted)}
  .vis-caption{position:absolute; right:.75rem; bottom:4.5rem; font-size:.8rem; color:var(--muted); opacity:.8}
  footer{padding: .5rem 1rem env(safe-area-inset-bottom); color:var(--muted); font-size:.85rem; display:flex; justify-content:space-between; gap:.75rem; align-items:center}
  .kbd{padding:.15rem .4rem; border:1px solid var(--grid); border-bottom-width:2px; border-radius:6px; background:var(--card); font-family:ui-monospace,monospace; font-weight:700}
  .sr{position:absolute; left:-9999px; width:1px; height:1px; overflow:hidden}
  .pill{border:1px dashed var(--grid); padding:.35rem .6rem; border-radius:999px; color:var(--muted)}
  @media (prefers-reduced-motion: reduce){ *{animation:none!important; transition:none!important} }
</style>
</head>
<body>
<div class="app" data-theme="dark" id="app">
  <header>
    <div class="bar" role="toolbar" aria-label="Controls">
      <div class="title">ðŸŽ§ Echoes & Algorithms</div>
      <span class="pill">W07 Â· Soundscapes Â· Orality Â· Perception</span>
      <div class="spacer"></div>
      <button id="btnStart" class="cta" aria-label="Start performance (Space)">Start</button>
      <button id="btnPause" aria-label="Pause/Resume performance (P)" disabled>Pause</button>
      <button id="btnRestart" aria-label="Restart performance" disabled>Restart</button>
      <button id="btnTheme" class="icon" aria-label="Toggle theme">ðŸŒ“</button>
    </div>
  </header>

  <main class="main">
    <canvas id="viz" aria-hidden="true"></canvas>
    <div class="overlay">
      <div class="center">
        <section class="now" aria-live="polite" aria-atomic="true">
          <div class="cue" id="cueTag">Ready Â· Tap Start</div>
          <h1 id="cueTitle">The room hums; silence arranges itself.</h1>
          <p id="cueDesc">This performance stages Ong, Schafer, Cage, Herndon, Haskell, Sterne, architecture, and ethics. Show, donâ€™t tell.</p>
        </section>
      </div>
      <div class="bottom">
        <div class="transport">
          <div class="meters">
            <label class="meter">Volume
              <input id="vol" type="range" min="0" max="1" step="0.01" value="0.8" aria-label="Master volume"/>
            </label>
            <label class="meter">TTS Rate
              <input id="rate" type="range" min="0.6" max="1.2" step="0.01" value="0.95" aria-label="Speech rate"/>
            </label>
            <label class="meter">TTS Pitch
              <input id="pitch" type="range" min="0.6" max="1.4" step="0.01" value="1.0" aria-label="Speech pitch"/>
            </label>
          </div>
          <div class="spacer"></div>
          <div style="min-width:220px; flex:1; max-width:700px">
            <div class="progress" aria-hidden="true"><i id="prog"></i></div>
            <div class="legend"><span id="status">Idle</span><span class="spacer"></span><span id="time">00:00</span></div>
          </div>
        </div>
      </div>
      <div class="vis-caption">visualizer: spectrum + particles (Web Audio)</div>
    </div>
    <div class="sr" id="captions" aria-live="polite"></div>
  </main>

  <footer>
    <div>
      <span class="kbd">Space</span> Start/Stop Â· <span class="kbd">P</span> Pause/Resume Â· <span class="kbd">R</span> Restart
    </div>
    <div>No external assets. TTS + synthesized tones + procedural ambience.</div>
  </footer>
</div>

<script>
(() => {
  // --- State & Utilities ---
  const $ = sel => document.querySelector(sel);
  const app = $('#app');
  const el = { start: $('#btnStart'), pause: $('#btnPause'), restart: $('#btnRestart'), theme: $('#btnTheme'),
               vol: $('#vol'), rate: $('#rate'), pitch: $('#pitch'),
               cueTag: $('#cueTag'), cueTitle: $('#cueTitle'), cueDesc: $('#cueDesc'),
               prog: $('#prog'), status: $('#status'), time: $('#time'), cap: $('#captions'), canvas: $('#viz') };

  let audioCtx, master, analyser, visData, started=false, running=false, paused=false, startTime=0, elapsed=0;
  const voices = { current: null };

  function fmtTime(sec){ sec = Math.max(0, sec|0); const m = String((sec/60|0)).padStart(2,'0'); const s = String(sec%60).padStart(2,'0'); return `${m}:${s}` }
  function setTheme(next){ app.dataset.theme = next; localStorage.setItem('echo-theme', next); }
  setTheme(localStorage.getItem('echo-theme') || 'dark');

  // --- Web Audio Graph (no external libs) ---
  function initAudio(){
    if(audioCtx) return;
    audioCtx = new (window.AudioContext || window.webkitAudioContext)({ latencyHint:'interactive' });
    master = audioCtx.createGain(); master.gain.value = parseFloat(el.vol.value);
    analyser = audioCtx.createAnalyser(); analyser.fftSize = 2048; visData = new Uint8Array(analyser.frequencyBinCount);
    const comp = audioCtx.createDynamicsCompressor();
    master.connect(comp); comp.connect(analyser); analyser.connect(audioCtx.destination);
  }

  function tone(freq=220, type='sine', dur=1.2, gain=0.2, pan=0){
    const osc = audioCtx.createOscillator(); osc.type = type; osc.frequency.value = freq;
    const g = audioCtx.createGain(); g.gain.value = 0; const p = new StereoPannerNode(audioCtx,{pan});
    osc.connect(g).connect(p).connect(master);
    const now = audioCtx.currentTime; g.gain.linearRampToValueAtTime(gain, now+0.02);
    g.gain.exponentialRampToValueAtTime(0.0001, now+dur);
    osc.start(); osc.stop(now+dur+0.05);
  }
  function chord(freqs=[220,277,330], dur=2, baseGain=0.12){
    freqs.forEach((f,i)=> tone(f, ['sine','triangle','sawtooth'][i%3], dur*(1+Math.random()*0.1), baseGain*(0.8+Math.random()*0.4), (i-1)*0.25));
  }
  function hiss(dur=2.5, level=0.12, pan=0){
    const bufferSize = 2 * audioCtx.sampleRate * dur;
    const buffer = audioCtx.createBuffer(1, bufferSize, audioCtx.sampleRate);
    const data = buffer.getChannelData(0);
    for(let i=0;i<buffer.length;i++){ data[i] = (Math.random()*2-1) * (1 - i/buffer.length); }
    const src = audioCtx.createBufferSource(); src.buffer = buffer;
    const g = audioCtx.createGain(); g.gain.value = level; const p = new StereoPannerNode(audioCtx,{pan});
    src.connect(g).connect(p).connect(master); src.start();
  }
  function ping(delay=0.25, reps=4){
    // tiny feedback delay ping to simulate space
    const d = audioCtx.createDelay(1.0); d.delayTime.value = delay;
    const g = audioCtx.createGain(); g.gain.value = 0.28;
    const tap = audioCtx.createGain(); tap.gain.value = 0.6;
    tap.connect(d); d.connect(g); g.connect(tap); // feedback loop
    tap.connect(master);
    for(let i=0;i<reps;i++){ setTimeout(()=> tone(660, 'sine', .1, .25), i*delay*750); }
  }

  function bed(duration=6, base=110){
    // evolving ambient pad
    const voices=4; for(let i=0;i<voices;i++){
      const f = base*(1 + (i*0.12)) * (0.98 + Math.random()*0.04);
      tone(f, i%2?'triangle':'sine', duration*(.85+Math.random()*0.25), 0.08, (i-1.5)*0.22);
    }
    hiss(duration, 0.04, 0);
  }

  // --- Speech Synthesis ---
  function pickVoice(){
    const list = window.speechSynthesis?.getVoices?.() || [];
    // Prefer an English voice that sounds relatively neutral; fall back otherwise.
    const preferred = list.find(v=> /en-?(US|GB|AU|CA|IN)/i.test(v.lang) && /female|google|enhanced|neural/i.test(v.name)) ||
                      list.find(v=> /en/i.test(v.lang)) || list[0] || null;
    voices.current = preferred;
  }
  window.speechSynthesis?.addEventListener?.('voiceschanged', pickVoice);
  pickVoice();

  function speak(text, {rate=+el.rate.value, pitch=+el.pitch.value, volume=1.0}={}){
    return new Promise(resolve => {
      if(!('speechSynthesis' in window)){ resolve(); return; }
      const u = new SpeechSynthesisUtterance(text);
      if(voices.current) u.voice = voices.current;
      u.rate = rate; u.pitch = pitch; u.volume = Math.min(1, Math.max(0, volume));
      u.onend = resolve; u.onerror = resolve; window.speechSynthesis.speak(u);
      // also push to captions for accessibility
      el.cap.textContent = text;
    });
  }

  // --- Visualizer ---
  const ctx2d = el.canvas.getContext('2d');
  let particles = new Array(240).fill(0).map(()=>({x:Math.random(), y:Math.random(), v:(Math.random()*0.002)+0.0005, r:Math.random()*2+0.5}));
  function draw(){
    const w = el.canvas.width = el.canvas.clientWidth * devicePixelRatio;
    const h = el.canvas.height = el.canvas.clientHeight * devicePixelRatio;
    ctx2d.clearRect(0,0,w,h);
    // background grid
    ctx2d.globalAlpha = 0.5; ctx2d.strokeStyle = getComputedStyle(document.documentElement).getPropertyValue('--grid');
    ctx2d.lineWidth = 1*devicePixelRatio; const step = 48*devicePixelRatio;
    for(let x=0;x<w; x+=step){ ctx2d.beginPath(); ctx2d.moveTo(x,0); ctx2d.lineTo(x,h); ctx2d.stroke(); }
    for(let y=0;y<h; y+=step){ ctx2d.beginPath(); ctx2d.moveTo(0,y); ctx2d.lineTo(w,y); ctx2d.stroke(); }

    // spectrum bars
    if(analyser){ analyser.getByteFrequencyData(visData); }
    const bars = visData ? visData.length : 0; const bw = Math.max(1, (w/(bars||1)));
    ctx2d.globalAlpha = 0.25; ctx2d.fillStyle = getComputedStyle(document.documentElement).getPropertyValue('--accent');
    for(let i=0;i<bars;i+=3){ const val = visData[i]/255; const bh = val*h*0.35; ctx2d.fillRect(i*bw, h-bh, bw*0.7, bh); }

    // floating particles reacting to spectrum energy
    ctx2d.globalAlpha = 0.9; ctx2d.fillStyle = getComputedStyle(document.documentElement).getPropertyValue('--accent2');
    const energy = visData ? visData[20]/255 : 0.1;
    particles.forEach(p=>{
      p.y += p.v * (0.5 + energy*1.5); if(p.y>1) p.y=0, p.x=Math.random();
      const x = p.x*w, y = p.y*h; const r = p.r*devicePixelRatio*(1+energy*0.8);
      ctx2d.beginPath(); ctx2d.arc(x,y,r,0,Math.PI*2); ctx2d.fill();
    });

    requestAnimationFrame(draw);
  }
  draw();

  // --- Timeline Engine ---
  const TL = [];
  function cue(tag, title, desc, fn){ TL.push({tag,title,desc,fn}); }

  // Content cues (short quotes <= ~20 words)
  cue('Prologue','The room hums; silence arranges itself.', 'Breathe. We will listen by composing the room.', async ()=>{
    bed(5, 96); ping(0.27,3); await speak('Welcome. This is a staged listening. Show, not tell.');
  });

  cue('Ong Â· Orality','Words are occurrences â€” events.','We begin with voice before text.', async ()=>{
    bed(7, 110); chord([220,277,330],3); await speak('Walter Ong reminds us. Words are events.');
    await speak('Try to hear meaning arrive as sound, not letters.');
  });

  cue('Schafer Â· Soundscape','Hi fi and lo fi, attention as distance.','Urban immediacy vs rural perspective â€” then, a third space.', async ()=>{
    hiss(4, .08, -0.4); tone(180,'sine',1,.06,-.6); tone(340,'triangle',1.2,.05,.6);
    await speak('R. Murray Schafer maps our sonic environment.');
    await speak('Beyond hi fi and lo fi, algorithms now arrange attention.');
  });

  cue('99% Invisible','Modern conveniences need sonic feedback.','Interface tones become infrastructure.', async ()=>{
    tone(880,'sine',.08,.22); setTimeout(()=>tone(1320,'triangle',.08,.16),120);
    await speak('Modern conveniences would be hard to use without sonic feedback.');
  });

  cue('Cage Â· Silence','Silence is a change of mind.','Absence becomes presence; attend to the room.', async ()=>{
    await speak('John Cage: silence does not exist.');
    await waitSilence(4.0, 'Structured quiet'); // ritual pause
    ping(0.35,2);
  });

  cue('Herndon Â· Uncanny Voice','Alien song craft, new communion.','Human and machine sing through each other.', async ()=>{
    chord([440,554,659],2.8,0.1); await speak('At the boundary of human and machine, voices blur.');
    await robot('This is almost a human voice. Almost.');
  });

  cue('Linguistic Relativity','Pitch feels high or low by language.','Perception carries grammar within it.', async ()=>{
    tone(440,'sine',.5,.12,-.3); await speak('Language shapes how pitch lives in space.');
  });

  cue('Haskell Â· Evolution','Many ancestors flow to the air.','Temporal soundscape: geology, biology, technology.', async ()=>{
    bed(6, 82); await speak('Listening is old. Crickets, forests, cities, servers. Layers.');
  });

  cue('Sterne Â· Audile Technique','Listening is historical all the way down.','Machine listening choreographs human listening.', async ()=>{
    await speak('Technologies crystallize cultural practice. The ear taught the microphone.');
    await speak('Now algorithms teach us how to hear each other.');
  });

  cue('Architecture Â· Reverb','Space scripts behavior.','Tiles, stairs, pads â€” acoustic politics.', async ()=>{
    ping(0.22,5); await speak('Architecture stages sound: reflections invite or refuse intimacy.');
  });

  cue('Ethics Â· Attention','Who owns the room of your listening?','Toward community sonic governance.', async ()=>{
    await speak('Platforms optimize for capture. We can optimize for care.');
  });

  cue('Clark Â· Closing','We are natural born cyborgs.','Extend mind, but choose the pattern.', async ()=>{
    chord([262,330,392,523],3,0.1); await speak('Compose your environment. Listen critically. Then, redesign.');
  });

  // small helper to speak with a robot-ish pitch/timbre
  async function robot(text){ await speak(text,{rate:0.92, pitch:1.25, volume:1}); }
  function waitSilence(s=3, note=''){
    return new Promise(res=>{ el.cap.textContent = `[silence] ${note}`; setTimeout(res, s*1000); });
  }

  // --- Runner ---
  async function run(){
    if(!audioCtx) initAudio();
    if(audioCtx.state==='suspended') await audioCtx.resume();
    started=true; running=true; paused=false; startTime = performance.now()-elapsed; updateButtons();
    for(let i=0;i<TL.length && running; i++){
      const c = TL[i]; updateCue(c.tag,c.title,c.desc, i/TL.length*100);
      // pre-bed for each section for continuity
      bed(4, 96+((i%5)*12));
      await c.fn();
      // if paused mid-cue, hold here until resumed
      if(!running) break;
    }
    if(running){ updateCue('End','The piece is finished.','Thank you for listening.',100); running=false; updateButtons(); }
  }

  function updateCue(tag, title, desc, pct){ el.cueTag.textContent = tag; el.cueTitle.textContent = title; el.cueDesc.textContent = desc; el.prog.style.width = `${pct||0}%`; el.status.textContent = running? 'Playing' : 'Idle'; }
  function updateButtons(){ el.start.disabled = started; el.pause.disabled = !started; el.restart.disabled = !started; el.pause.textContent = paused? 'Resume':'Pause'; }

  function tick(){ if(started && !paused){ elapsed = performance.now()-startTime; el.time.textContent = fmtTime(elapsed/1000); } requestAnimationFrame(tick); }
  tick();

  // --- Events ---
  el.start.addEventListener('click', ()=>run());
  el.pause.addEventListener('click', async ()=>{
    if(!started) return; paused = !paused; el.pause.textContent = paused? 'Resume':'Pause';
    if(paused){ running=false; window.speechSynthesis?.cancel(); await audioCtx.suspend(); el.status.textContent='Paused'; }
    else { running=true; await audioCtx.resume(); startTime = performance.now()-elapsed; el.status.textContent='Playing'; run(); }
  });
  el.restart.addEventListener('click', async ()=>{ window.speechSynthesis?.cancel(); running=false; paused=false; started=false; elapsed=0; el.time.textContent='00:00'; el.prog.style.width='0%'; updateButtons(); updateCue('Prologue','The room hums; silence arranges itself.','Breathe. We will listen by composing the room.',0); });
  el.theme.addEventListener('click', ()=> setTheme(app.dataset.theme==='dark'?'light':'dark'));
  el.vol.addEventListener('input', e=>{ if(master) master.gain.value = parseFloat(e.target.value); localStorage.setItem('echo-vol', e.target.value); });
  el.rate.addEventListener('input', e=> localStorage.setItem('echo-rate', e.target.value));
  el.pitch.addEventListener('input', e=> localStorage.setItem('echo-pitch', e.target.value));
  // restore prefs
  ['vol','rate','pitch'].forEach(k=>{ const v = localStorage.getItem(`echo-${k}`); if(v) el[k].value = v; });

  // Keyboard shortcuts
  window.addEventListener('keydown', (ev)=>{
    if(ev.code==='Space'){ ev.preventDefault(); if(!started) el.start.click(); else el.pause.click(); }
    if(ev.key==='p' || ev.key==='P'){ el.pause.click(); }
    if(ev.key==='r' || ev.key==='R'){ el.restart.click(); }
  });
})();
</script>
</body>
</html>
